{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search on Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ml_helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import bucketized data:\n",
    "#data = ml_helpers.convert_to_categorical(data, [columns_to_convert])\n",
    "#If bucketized data doesn't have spatial lag, make it have spatial lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_results(model, model_name, grid_params, scoring, X_train, y_train):\n",
    "    '''\n",
    "    Runs gridsearch for data on a given year to find best hyperparameters\n",
    "    Inputs:\n",
    "        Model: sklearn model object\n",
    "        grid_params (dict): maps hyperparameters to potential options\n",
    "        scoring (list of strings): a list of the ways to score\n",
    "    Ouputs:\n",
    "        results (pd.DataFrame): the cross-validated scores for each model\n",
    "    '''\n",
    "    gridsearch = GridSearchCV(model, \n",
    "                          grid_params, \n",
    "                          scoring = scoring, \n",
    "                          cv=10, \n",
    "                          n_jobs=-1)\n",
    "    fit = gridsearch.fit(X_train, y_train)\n",
    "    results = pd.DataFrame(fit.cv_results_)\n",
    "    results = results[[\"params\", \"mean_test_f1\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_grid_searches(model, model_name, \n",
    "                          grid_params, scoring, \n",
    "                          data, test_year, \n",
    "                          num_years_in_train, vars_to_onehot):\n",
    "    '''\n",
    "    Model: sklearn model object\n",
    "    model_name (string): a name for the model\n",
    "    grid_params (dict): maps hyperparameters to potential options\n",
    "    scoring (list of strings): a list of the ways to score\n",
    "    data (pd.DataFrame): a pandas dataframe with all the data\n",
    "    test_year (int): The year we seek to predict\n",
    "    num_years_in_train (int): The number of years before the test year to \n",
    "        use to predict the test year\n",
    "    vars_to_onehot (list of strings): A list of strings of variables to onehot encode\n",
    "    \n",
    "    Idea to concatenate rows of dfs came via the first answer on from this stack exchange: \n",
    "    https://stackoverflow.com/questions/44515888/compute-average-mean-across-dataframes-in-python-pandas\n",
    "    \n",
    "    Get mean of col rows help from here: \n",
    "    https://stackoverflow.com/questions/33750326/compute-row-average-in-pandas\n",
    "    '''\n",
    "    target_years_in_train = list(np.arange(2015,test_year))\n",
    "    target_years_in_train.pop(0)\n",
    "    \n",
    "    results_dfs = []\n",
    "    \n",
    "    for target_year in target_years_in_train:\n",
    "        train_df, train_y, test_df, test_y = prep_data(df, y, \n",
    "                                                       taget_year, num_years_in_train, \n",
    "                                                       vars_to_onehot)\n",
    "        results_df = grid_search_results(model, model_name, \n",
    "                                         grid_params, scoring, \n",
    "                                         X_train, y_train)\n",
    "        results_dfs.append(results_df)\n",
    "    \n",
    "    all_results = pd.concat(results_dfs, axis = 1)\n",
    "    all_results['mean'] = all_results.mean(axis=1)\n",
    "    all_results.sort_values(\"mean\", inplace=True, ascending=False)\n",
    "    results_to_return = all_results[\"params\", 'mean'].sort_values(\"mean\")\n",
    "    return results_to_return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4.0\n",
       "0    3.0\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test that most grid_search code works:\n",
    "d = pd.DataFrame({'col1': [1, 2]})\n",
    "e = pd.DataFrame({\"col1\": [3, 4]})\n",
    "f = pd.DataFrame({\"col1\":[5, 6]})\n",
    "\n",
    "all = pd.concat([d, e, f], axis=1)\n",
    "all['mean'] = all.mean(axis=1)\n",
    "all.sort_values(\"mean\", inplace=True, ascending=False)\n",
    "results_to_return = all['mean']\n",
    "\n",
    "\n",
    "results_to_return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
