{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers to Run ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_mean(df_train, df_to_fill):\n",
    "    '''\n",
    "    df['value'] = df['value'].fillna(df.groupby('name')['value'].transform('mean'))\n",
    "\n",
    "    A simple function that fills missing values of continuous columns \n",
    "        with the column median\n",
    "    Inputs:\n",
    "        df_train (df): the training df. Function computes means from this value AND fills this \n",
    "        df_to_fill (df): the df whose continuous NAs should be filled \n",
    "    Returns:\n",
    "        df_train (df): the training dataset\n",
    "        df_to_fill: the testing dataset with its data filled by the training data median\n",
    "\n",
    "    '''\n",
    "    df_train_num = df_train.select_dtypes(include=[np.number])\n",
    "    #means = df_train_num.mean().to_dict()\n",
    "    \n",
    "    for col in df_train_num.columns:\n",
    "        df_train[col] = df_train.groupby(\"Year\").transform(lambda x: x.fillna(x.mean()))\n",
    "        df_to_fill[col] = df_to_fill.groupby(\"Year\").transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    #df_train = df_train.fillna(value=means)\n",
    "    #df_to_fill = df_to_fill.fillna(value=means)\n",
    "    print(\"Finished filling NAs with mean...\")\n",
    "    return df_train, df_to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished filling NAs with mean...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value2</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  value2 Year\n",
       "0    1.0     1.0    A\n",
       "1    1.0     1.0    A\n",
       "2    2.0     2.0    B\n",
       "3    2.0     2.0    B\n",
       "4    3.0     3.0    B\n",
       "5    1.0     1.0    B\n",
       "6    3.0     3.0    C\n",
       "7    3.0     3.0    C\n",
       "8    3.0     3.0    C"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing above function\n",
    "#df_train = pd.DataFrame({'value': [1, np.nan, np.nan, 2, 3, 1, 3, np.nan, 3], \"value2\":[1, 2, 3, 4, 5, np.nan, 7, 8, 9], 'Year': ['A','A', 'B','B','B','B', 'C','C','C']})\n",
    "#df_to_fill = pd.DataFrame({'value': [1, np.nan, np.nan, 2, 3, 1, 3, np.nan, 3], 'Year': ['A','A', 'A','A','A','A', 'A','A','A']})\n",
    "#df_train, df_to_fill = fill_missing_mean(df_train, df_to_fill)\n",
    "#df_to_fill\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_continuous(df, scaler = None):\n",
    "    '''\n",
    "    A simple function that normalizes the values of of continuous columns \n",
    "        using data from the training set\n",
    "    Inputs:\n",
    "        df (df): either the training or the testing df\n",
    "        scaler: the scaler object. It will be None for training and exist for testing \n",
    "    Returns:\n",
    "        df (df): the standardized df\n",
    "        scaler: the scaler object\n",
    "    '''\n",
    "    if scaler is None: #Training case\n",
    "        scaler = sk.preprocessing.StandardScaler() #Set up scaler\n",
    "        df_num = df.select_dtypes(include=[np.number]) #find numeric columns\n",
    "        df_num_scaled = scaler.fit_transform(df_num) #Normalize them\n",
    "        df_num_cols = list(df_num.columns) \n",
    "        df.loc[:, df_num_cols] = df_num_scaled #Insert columns back into the main df \n",
    "        print(\"Finished normalizing training data\")\n",
    "    else: #Testing case\n",
    "        df_num = df.select_dtypes(include=[np.number]) #find numeric columns\n",
    "        df_num_scaled = scaler.transform(df_num) #Normalize them\n",
    "        df_num_cols = list(df_num.columns) \n",
    "        df.loc[:, df_num_cols] = df_num_scaled #Insert columns back into the main df \n",
    "        print(\"Finished normalizing test data...\")\n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, cat_vars): \n",
    "    '''\n",
    "    A function to one-hot encode given categorical variables\n",
    "    Inputs:\n",
    "        df (df): a pandas dataframe\n",
    "        cat_vars (list of strings): a list of the categorical variables to one-hot encode\n",
    "    '''\n",
    "\n",
    "    df = pd.get_dummies(df, columns = cat_vars)\n",
    "    print(\"finished one-hot encoding...\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(train, test):\n",
    "    '''\n",
    "    A function to ensure that training and testing data have identical columns\n",
    "    after one-hot encoding\n",
    "    If a column is in training but not testing, adds a column of 0s to testing\n",
    "    If column is in testing but not training, it is removed\n",
    "    Inputs:\n",
    "        train (df): the training df\n",
    "        test (df): the testing df\n",
    "    Outputs:\n",
    "        train, test (df): the datasets with identical columns\n",
    "    '''\n",
    "    train_cols = list(train.columns)\n",
    "    test_cols = list(test.columns)\n",
    "    \n",
    "    for tr_col in train_cols:\n",
    "        if tr_col not in test_cols:\n",
    "            test[tr_col] = 0\n",
    "    \n",
    "    for test_col in test_cols:\n",
    "        if test_col not in train_cols:\n",
    "            test = test.drop(test_col, axis=1)\n",
    "    print(\"finished standardizing...\")\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1           True\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1542559    False\n",
       "1542560    False\n",
       "1542561    False\n",
       "1542562    False\n",
       "1542563    False\n",
       "Name: Arrest, Length: 1542564, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_train_test_by_year(df, y, test_year, num_years):\n",
    "    '''\n",
    "    isin syntax from: https://www.kite.com/python/answers/how-to-filter-a-pandas-dataframe-with-a-list-by-%60in%60-or-%60not-in%60-in-python\n",
    "    Inputs:\n",
    "        df (df): the dataframe with both the X and y \n",
    "        y (string): the column name in the df that is the target\n",
    "        test_year(int): the year we seek to predict in 2016-2020\n",
    "        num_years(int): the number of years to be included in the training set\n",
    "\n",
    "    Output:\n",
    "    train_df (df): A training dataframe\n",
    "    test_X (df): Testing df of predictors\n",
    "    test_y (df): Testing target\n",
    "    '''\n",
    "    year_range = np.arange(test_year - num_years, test_year)\n",
    "    train_filter = df.Year.isin(year_range)\n",
    "    train_df = df[train_filter]\n",
    "    train_X = train_df.drop(columns=[y])\n",
    "    print(train_df.columns)\n",
    "    train_y = train_df[y]\n",
    "    \n",
    "    test_df = df[df.Year==test_year]\n",
    "    test_X = test_df.drop(columns = [y])\n",
    "    test_y = test_df[y]\n",
    "    print(\"finished splitting by year...\")\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "#split_train_test_by_year(data, \"Arrest\", 2017, 2)\n",
    "data[\"Arrest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, y, test_year, num_years, vars_to_onehot):\n",
    "    '''\n",
    "    Helper function that aggregates the above helpers to prepare for imputation in \n",
    "    an ML algorithm. Specifically this:\n",
    "        Splits the training set and testing set based on year \n",
    "            using split_train_test_by_year\n",
    "        One-hot encodes and standardizes the columns using \n",
    "            one_hot_encode and standardize_column\n",
    "        Normalizes all continuous variables using normalize_continuous\n",
    "    Inputs:\n",
    "    df (pandas DataFrame): the dataframe with training and testing data, predictors and target\n",
    "    y (string): the name of the target column\n",
    "    num_years (int): the number of years to be included in the training set\n",
    "    test_year (int): the year we seek to predict 2015_2020\n",
    "    \n",
    "    Outputs:\n",
    "    train_df (df): a standardized training set with one-hot encorded categorical columns\n",
    "    test_df (df): the test dataframe, again standardized as above\n",
    "    test_y (Series): the test target\n",
    "    '''\n",
    "    train_df, train_y, test_df, test_y = split_train_test_by_year(df, y, test_year, num_years)\n",
    "    train_df, test_df = fill_missing_mean(train_df, test_df)\n",
    "    train_df, scaler = normalize_continuous(train_df)\n",
    "    test_df, doesnt_matter = normalize_continuous(test_df, scaler)\n",
    "    train_df = one_hot_encode(train_df, vars_to_onehot)\n",
    "    test_df = one_hot_encode(test_df, vars_to_onehot)\n",
    "    train_df, test_df = standardize_columns(train_df, test_df)\n",
    "    return train_df, train_y, test_df, test_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Watch</th>\n",
       "      <th>...</th>\n",
       "      <th>count_metra_stops</th>\n",
       "      <th>count_restaurants</th>\n",
       "      <th>count_bars</th>\n",
       "      <th>count_daycares</th>\n",
       "      <th>count_entertainment</th>\n",
       "      <th>count_businesses</th>\n",
       "      <th>road_distance_ft</th>\n",
       "      <th>TOTAL POPULATION</th>\n",
       "      <th>dist_to_police</th>\n",
       "      <th>dist_to_hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10225520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>411</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>231176.656022</td>\n",
       "      <td>5470.665022</td>\n",
       "      <td>7180.695576</td>\n",
       "      <td>2783.222325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11028448</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1532</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>162950.259395</td>\n",
       "      <td>6459.881637</td>\n",
       "      <td>5701.676947</td>\n",
       "      <td>6619.369443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10225760</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>84982.042393</td>\n",
       "      <td>11195.685856</td>\n",
       "      <td>9224.617641</td>\n",
       "      <td>989.984955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11242929</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>223</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>132102.433573</td>\n",
       "      <td>7269.595612</td>\n",
       "      <td>5686.009943</td>\n",
       "      <td>1509.833687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10229179</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>214</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>First</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>179945.426889</td>\n",
       "      <td>6796.787190</td>\n",
       "      <td>6120.288930</td>\n",
       "      <td>6801.558784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Arrest  Domestic  Beat  Year  Month  Week  Day  Hour  Watch  ...  \\\n",
       "0  10225520   False     False   411  2015      1     1    1     0  First  ...   \n",
       "1  11028448    True      True  1532  2015      1     1    1     0  First  ...   \n",
       "2  10225760   False     False  2024  2015      1     1    1     0  First  ...   \n",
       "3  11242929   False     False   223  2015      1     1    1     0  First  ...   \n",
       "4  10229179   False     False   214  2015      1     1    1     0  First  ...   \n",
       "\n",
       "   count_metra_stops  count_restaurants  count_bars  count_daycares  \\\n",
       "0                2.0               16.0         0.0             1.0   \n",
       "1                0.0               14.0         2.0             1.0   \n",
       "2                0.0               36.0         7.0             2.0   \n",
       "3                0.0               21.0         3.0             0.0   \n",
       "4                0.0               11.0         2.0             2.0   \n",
       "\n",
       "  count_entertainment count_businesses  road_distance_ft  TOTAL POPULATION  \\\n",
       "0                 0.0             58.0     231176.656022       5470.665022   \n",
       "1                 0.0             24.0     162950.259395       6459.881637   \n",
       "2                 0.0             50.0      84982.042393      11195.685856   \n",
       "3                 1.0             30.0     132102.433573       7269.595612   \n",
       "4                 2.0             48.0     179945.426889       6796.787190   \n",
       "\n",
       "   dist_to_police  dist_to_hospital  \n",
       "0     7180.695576       2783.222325  \n",
       "1     5701.676947       6619.369443  \n",
       "2     9224.617641        989.984955  \n",
       "3     5686.009943       1509.833687  \n",
       "4     6120.288930       6801.558784  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../intermediate_data/df_2015_to_present.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, cols_to_convert):\n",
    "    '''\n",
    "    Convert columns to categorical\n",
    "    Inputs:\n",
    "        df (pd.DataFrame): The Pandas df\n",
    "        cols_to_convert (list of strings): The columns to convert    \n",
    "    Output:\n",
    "        df - the updated dataframe\n",
    "    '''\n",
    "    for col in cols_to_convert:\n",
    "        df[col]=df[col].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "data = convert_to_categorical(data, [\"Beat\", \"Year\", \"Month\", \"Watch\"])\n",
    "data[\"Arrest_target\"]=np.where(data[\"Arrest\"] is True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Arrest', 'Domestic', 'Beat', 'Year', 'Month', 'Week', 'Day',\n",
      "       'Hour', 'Watch', 'PRCP', 'SNOW', 'TMAX', 'TMIN', 'category_1',\n",
      "       'category_2', 'count_l_stops', 'count_bus_stops', 'count_metra_stops',\n",
      "       'count_restaurants', 'count_bars', 'count_daycares',\n",
      "       'count_entertainment', 'count_businesses', 'road_distance_ft',\n",
      "       'TOTAL POPULATION', 'dist_to_police', 'dist_to_hospital'],\n",
      "      dtype='object')\n",
      "finished splitting by year...\n",
      "Finished filling NAs with mean...\n",
      "Finished normalizing training data\n",
      "Finished normalizing test data...\n",
      "finished one-hot encoding...\n",
      "finished one-hot encoding...\n",
      "finished standardizing...\n"
     ]
    }
   ],
   "source": [
    "#Test the code! \n",
    "train_X, train_y, test_X, test_y = prep_data(data, \"Arrest\", 2017, 2, \n",
    "                                       [\"Year\", \"Month\", \"Week\", \"Beat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.describe() #Looking fresh :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
