{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers to Run ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_mean(df_train, df_to_fill):\n",
    "    '''\n",
    "    A simple function that fills missing values of continuous columns \n",
    "        with the column median\n",
    "    Inputs:\n",
    "        df_train (df): the training df. Function computes means from this value AND fills this \n",
    "        df_to_fill (df): the df whose continuous NAs should be filled \n",
    "    Returns:\n",
    "        df_train (df): the training dataset\n",
    "        df_to_fill: the testing dataset with its data filled by the training data median\n",
    "\n",
    "    '''\n",
    "    df_train_num = df_train.select_dtypes(include=[np.number])\n",
    "    #means = df_train_num.mean().to_dict()\n",
    "    mean_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for col in df_train_num.columns:\n",
    "        mean_dict[col] = df_train[col].mean()\n",
    "    \n",
    "    df_train.fillna(value=mean_dict, inplace=True)\n",
    "    df_to_fill.fillna(value=mean_dict, inplace=True)\n",
    "    \n",
    "    #df_train = df_train.fillna(value=means)\n",
    "    #df_to_fill = df_to_fill.fillna(value=means)\n",
    "    print(\"Finished filling NAs with mean...\")\n",
    "    return df_train, df_to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing above function\n",
    "\n",
    "#df_train = pd.DataFrame({'value': [1, np.nan, np.nan, 2, 3, 1, 3, np.nan, 3], \"value2\":[1, 2, 3, 4, 5, np.nan, 7, 8, 9], 'Year': ['A','A', 'B','B','B','B', 'C','C','C']})\n",
    "#df_to_fill = pd.DataFrame({'value': [1, np.nan, np.nan, 2, 3, 1, 3, np.nan, 3], \"value2\":[10, 20, 33, 43, 53, np.nan, 7, 8, 9], 'Year': ['A','A', 'B','B','B','B', 'C','C','C']})\n",
    "#df_train, df_to_fill = fill_missing_mean(df_train, df_to_fill)\n",
    "#df_to_fill\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_continuous(df, scaler = None):\n",
    "    '''\n",
    "    A simple function that normalizes the values of of continuous columns \n",
    "        using data from the training set\n",
    "    Inputs:\n",
    "        df (df): either the training or the testing df\n",
    "        scaler: the scaler object. It will be None for training and exist for testing \n",
    "    Returns:\n",
    "        df (df): the standardized df\n",
    "        scaler: the scaler object\n",
    "    '''\n",
    "    df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
    "    if scaler is None: #Training case\n",
    "        scaler = sk.preprocessing.StandardScaler() #Set up scaler\n",
    "        df_num = df.select_dtypes(include=[np.number]) #find numeric columns\n",
    "        df_num_scaled = scaler.fit_transform(df_num) #Normalize them\n",
    "        df_num_cols = list(df_num.columns) \n",
    "        df.loc[:, df_num_cols] = df_num_scaled #Insert columns back into the main df \n",
    "        print(\"Finished normalizing training data\")\n",
    "    else: #Testing case\n",
    "        df_num = df.select_dtypes(include=[np.number]) #find numeric columns\n",
    "        df_num_scaled = scaler.transform(df_num) #Normalize them\n",
    "        df_num_cols = list(df_num.columns) \n",
    "        df.loc[:, df_num_cols] = df_num_scaled #Insert columns back into the main df \n",
    "        print(\"Finished normalizing test data...\")\n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, cat_vars): \n",
    "    '''\n",
    "    A function to one-hot encode given categorical variables\n",
    "    Inputs:\n",
    "        df (df): a pandas dataframe\n",
    "        cat_vars (list of strings): a list of the categorical variables to one-hot encode\n",
    "    '''\n",
    "\n",
    "    df = pd.get_dummies(df, columns = cat_vars)\n",
    "    print(\"Finished one-hot encoding...\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(train, test):\n",
    "    '''\n",
    "    A function to ensure that training and testing data have identical columns\n",
    "    after one-hot encoding\n",
    "    If a column is in training but not testing, adds a column of 0s to testing\n",
    "    If column is in testing but not training, it is removed\n",
    "    Inputs:\n",
    "        train (df): the training df\n",
    "        test (df): the testing df\n",
    "    Outputs:\n",
    "        train, test (df): the datasets with identical columns\n",
    "    '''\n",
    "    train_cols = list(train.columns)\n",
    "    test_cols = list(test.columns)\n",
    "    \n",
    "    for tr_col in train_cols:\n",
    "        if tr_col not in test_cols:\n",
    "            test[tr_col] = 0\n",
    "    \n",
    "    for test_col in test_cols:\n",
    "        if test_col not in train_cols:\n",
    "            test = test.drop(test_col, axis=1)\n",
    "    print(\"Finished standardizing...\")\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_year(df, y, num_years, year_col):\n",
    "    '''\n",
    "    \n",
    "    Ultimately, this function divides the dataset up into smaller chunks with a one year test set and a num_years \n",
    "        years worth of training data in the num_years years just previous to the test year\n",
    "        \n",
    "    Ex: we are always predicting 2020 but remove that to see results later.\n",
    "        If num_years = 2 and the data runs from 2015 to 2020, this function creates data with:\n",
    "            \n",
    "            set 1:\n",
    "                Train: 2015 and 2016\n",
    "                Test: 2017\n",
    "            set 2:\n",
    "                Train: 2016 2017\n",
    "                Test: 2018\n",
    "            set 3:\n",
    "                Train: 2017 and 2018\n",
    "                Test: 2019\n",
    "    Inputs:\n",
    "        df (df): the dataframe with both the X and y \n",
    "        y (string): the column name in the df that is the target\n",
    "        num_years(int): the number of years to be included in the training set\n",
    "        year_col (str): the name of the column representing the years in the df\n",
    "    Output:\n",
    "   train_test_data_list (list of tuples):\n",
    "       each tuple contains:\n",
    "           df_train (DataFrame): includes num_years worth of data before the test year\n",
    "           df_test (DataFrame): includes 1 year, the test year for this set of data\n",
    "    '''\n",
    "    year_list = df[year_col].unique()\n",
    "    year_list = sorted(list(year_list), reverse=True)\n",
    "    year_list\n",
    "\n",
    "    train_test_data_list = []\n",
    "    for year in year_list:\n",
    "        if year - num_years in year_list:\n",
    "            df_test = df.loc[df[year_col]==year]\n",
    "            df_train = df.loc[(df[year_col] < year) & (df[year_col] >= year-num_years)]\n",
    "            train_test_data_list.append((df_train, df_test, year))\n",
    "            print(train_test_data_list[-1][0])\n",
    "    train_test_data_list.pop(0)\n",
    "    print(\"Finished splitting...\")\n",
    "    return train_test_data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_year_test(df, y, num_years, year_col):\n",
    "    '''\n",
    "    \n",
    "    Ultimately, this function divides the dataset up into smaller chunks with a one year test set and a num_years \n",
    "        years worth of training data in the num_years years just previous to the test year\n",
    "        \n",
    "    Ex: we are always predicting 2020 but remove that to see results later.\n",
    "        If num_years = 2 and the data runs from 2015 to 2020, this function creates data with:\n",
    "            \n",
    "            set 1:\n",
    "                Train: 2015 and 2016\n",
    "                Test: 2017\n",
    "            set 2:\n",
    "                Train: 2016 2017\n",
    "                Test: 2018\n",
    "            set 3:\n",
    "                Train: 2017 and 2018\n",
    "                Test: 2019\n",
    "    Inputs:\n",
    "        df (df): the dataframe with both the X and y \n",
    "        y (string): the column name in the df that is the target\n",
    "        num_years(int): the number of years to be included in the training set\n",
    "        year_col (str): the name of the column representing the years in the df\n",
    "    Output:\n",
    "   train_test_data_list (list of tuples):\n",
    "       each tuple contains:\n",
    "           df_train (DataFrame): includes num_years worth of data before the test year\n",
    "           df_test (DataFrame): includes 1 year, the test year for this set of data\n",
    "    '''\n",
    "    year_list = df[year_col].unique()\n",
    "    year_list = sorted(list(year_list), reverse=True)\n",
    "    year_list\n",
    "\n",
    "    train_test_data_list = []\n",
    "    for year in year_list:\n",
    "        if year - num_years in year_list:\n",
    "            df_test = df.loc[df[year_col]==year]\n",
    "            df_train = df.loc[(df[year_col] < year) & (df[year_col] >= year-num_years)]\n",
    "            train_test_data_list.append((df_train, df_test, year))\n",
    "            print(train_test_data_list[-1][0])\n",
    "    print(\"Finished splitting...\")\n",
    "    return train_test_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing above;\n",
    "#data_list = split_train_test_by_year(data, \"was_arrested\", 2, \"Year\")   \n",
    "#for group in data_list:\n",
    "#    print(group[0][\"Year\"].unique(), group[1][\"Year\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, y, num_years, year_col, vars_to_onehot, pca=None, columns_to_pca=None):\n",
    "    '''\n",
    "    Helper function that aggregates the above helpers to prepare for imputation in \n",
    "    an ML algorithm. Specifically this:\n",
    "        Splits the training set and testing set based on year \n",
    "            using split_train_test_by_year\n",
    "        One-hot encodes and standardizes the columns using \n",
    "            one_hot_encode and standardize_column\n",
    "        Normalizes all continuous variables using normalize_continuous\n",
    "    Inputs:\n",
    "    df (pandas DataFrame): the dataframe with training and testing data, predictors and target\n",
    "    y (string): the name of the target column\n",
    "    num_years (int): the number of years to be included in the training set\n",
    "    test_year (int): the year we seek to predict 2015_2020\n",
    "    \n",
    "    Outputs:\n",
    "    cleaned_train_test - a list of tuples. \n",
    "    The first tuple is the training dataframe and the second is the test for a given set of years\n",
    "    '''\n",
    "    df = convert_to_categorical(df, [y])\n",
    "    cleaned_trained_test = []\n",
    "    train_test_list = split_train_test_by_year_test(df, y, num_years, year_col)\n",
    "    for year_set in train_test_list:\n",
    "        print(\"Working on:\", year_set[0][\"Year\"].unique())\n",
    "        train_df = year_set[0]\n",
    "        test_df = year_set[1]\n",
    "        year = year_set[2]\n",
    "        print(\"Have accessed train and test df...\")\n",
    "        train_df, test_df = fill_missing_mean(train_df, test_df)\n",
    "        print(\"On to normalizing continuous...\")\n",
    "        train_df, scaler = normalize_continuous(train_df)\n",
    "        test_df, doesnt_matter = normalize_continuous(test_df, scaler)\n",
    "        train_df = one_hot_encode(train_df, vars_to_onehot)\n",
    "        test_df = one_hot_encode(test_df, vars_to_onehot)\n",
    "        train_df, test_df = standardize_columns(train_df, test_df)\n",
    "        \n",
    "        if pca is not None:\n",
    "            train_df, test_df = conduct_pca(train_df, test_df, columns_to_pca)\n",
    "        \n",
    "        cleaned_trained_test.append((train_df, test_df, year))\n",
    "        \n",
    "    return cleaned_trained_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_test(df, y, num_years, year_col, vars_to_onehot):\n",
    "    '''\n",
    "    This function is identical to the above except that it does not remove the last set of data\n",
    "    Thus, it should be used when computing final results of the best models\n",
    "    '''\n",
    "    df = convert_to_categorical(df, [y])\n",
    "    cleaned_trained_test = []\n",
    "    train_test_list = split_train_test_by_year_test(df, y, num_years, year_col)\n",
    "    for year_set in train_test_list:\n",
    "        print(\"Working on:\", year_set[0][\"Year\"].unique())\n",
    "        train_df = year_set[0]\n",
    "        test_df = year_set[1]\n",
    "        year = year_set[2]\n",
    "        print(\"Have accessed train and test df...\")\n",
    "        train_df, test_df = fill_missing_mean(train_df, test_df)\n",
    "        print(\"On to normalizing continuous...\")\n",
    "        train_df, scaler = normalize_continuous(train_df)\n",
    "        test_df, doesnt_matter = normalize_continuous(test_df, scaler)\n",
    "        train_df = one_hot_encode(train_df, vars_to_onehot)\n",
    "        test_df = one_hot_encode(test_df, vars_to_onehot)\n",
    "        train_df, test_df = standardize_columns(train_df, test_df)\n",
    "        \n",
    "        cleaned_trained_test.append((train_df, test_df, year))\n",
    "        \n",
    "    return cleaned_trained_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_pca(train_df, test_df, columns_to_pca):\n",
    "    '''\n",
    "    Function that performs pca on a set of specified columns\n",
    "    Inputs:\n",
    "        train_df (df): training dataframe\n",
    "        test_df (df): testing dataframe\n",
    "        columns_to_pca (list of strings): list of column names to perform pca\n",
    "                                          Note that these should not also be one-hotencoded\n",
    "        num_feature (int): Number of components to return\n",
    "    Outputs:\n",
    "        train_df(df): df with all of the columns in columns_to_pca combined to 2 cols\n",
    "        test_df(df):  df with all of the columns in columns_to_pca combined to 2 cols\n",
    "    '''\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(train_df[columns_to_pca])\n",
    "    \n",
    "    train_cols = pca.transform(train_df[columns_to_pca])\n",
    "    train_pca = pd.DataFrame(data=train_cols,\n",
    "                  columns = [\"principal component 1\",\n",
    "                             \"principal component 2\"])\n",
    "    train_df.drop(columns = columns_to_pca, inplace=True)\n",
    "    \n",
    "    print(train_pca[\"principal component 1\"].head(5))\n",
    "    print(train_pca.shape, train_df.shape)\n",
    "    \n",
    "    \n",
    "    train_df[\"PC 1\"] = train_pca[\"principal component 1\"].values\n",
    "    train_df[\"PC 2\"] = train_pca[\"principal component 2\"].values\n",
    "\n",
    "\n",
    "    \n",
    "    test_cols = pca.transform(test_df[columns_to_pca])\n",
    "    test_pca = pd.DataFrame(data=test_cols,\n",
    "                  columns = [\"principal component 1\",\n",
    "                             \"principal component 2\"])\n",
    "    test_df.drop(columns = columns_to_pca, inplace=True)\n",
    "    test_df[\"PC 1\"] = test_pca[\"principal component 1\"].values\n",
    "    test_df[\"PC 2\"] = test_pca[\"principal component 2\"].values\n",
    "    \n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, cols_to_convert):\n",
    "    '''\n",
    "    Convert columns to categorical\n",
    "    Inputs:\n",
    "        df (pd.DataFrame): The Pandas df\n",
    "        cols_to_convert (list of strings): The columns to convert    \n",
    "    Output:\n",
    "        df - the updated dataframe\n",
    "    '''\n",
    "    for col in cols_to_convert:\n",
    "        df[col]=df[col].astype(\"category\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>beat</th>\n",
       "      <th>beat_num</th>\n",
       "      <th>district</th>\n",
       "      <th>sector</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Watch</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Crimes</th>\n",
       "      <th>...</th>\n",
       "      <th>count_restaurants</th>\n",
       "      <th>count_bars</th>\n",
       "      <th>count_daycares</th>\n",
       "      <th>count_entertainment</th>\n",
       "      <th>count_businesses</th>\n",
       "      <th>road_distance_ft</th>\n",
       "      <th>TOTAL POPULATION</th>\n",
       "      <th>dist_to_police</th>\n",
       "      <th>dist_to_hospital</th>\n",
       "      <th>high_crime_geog_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1713</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>1713</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>169276.405792</td>\n",
       "      <td>13283.675264</td>\n",
       "      <td>5454.068890</td>\n",
       "      <td>3258.006066</td>\n",
       "      <td>0.155378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1713</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>1713</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>169276.405792</td>\n",
       "      <td>13283.675264</td>\n",
       "      <td>5454.068890</td>\n",
       "      <td>3258.006066</td>\n",
       "      <td>0.155378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1713</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>1713</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>169276.405792</td>\n",
       "      <td>13283.675264</td>\n",
       "      <td>5454.068890</td>\n",
       "      <td>3258.006066</td>\n",
       "      <td>0.155378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1713</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Second</td>\n",
       "      <td>1713</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>169276.405792</td>\n",
       "      <td>13283.675264</td>\n",
       "      <td>5454.068890</td>\n",
       "      <td>3258.006066</td>\n",
       "      <td>0.155378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1713</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Third</td>\n",
       "      <td>1713</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>169276.405792</td>\n",
       "      <td>13283.675264</td>\n",
       "      <td>5454.068890</td>\n",
       "      <td>3258.006066</td>\n",
       "      <td>0.155378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59088</th>\n",
       "      <td>59088</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>Third</td>\n",
       "      <td>312</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200633.844449</td>\n",
       "      <td>4144.689546</td>\n",
       "      <td>4843.037238</td>\n",
       "      <td>4374.482421</td>\n",
       "      <td>0.181185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59089</th>\n",
       "      <td>59089</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>First</td>\n",
       "      <td>312</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200633.844449</td>\n",
       "      <td>4144.689546</td>\n",
       "      <td>4843.037238</td>\n",
       "      <td>4374.482421</td>\n",
       "      <td>0.181185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59090</th>\n",
       "      <td>59090</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Third</td>\n",
       "      <td>312</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200633.844449</td>\n",
       "      <td>4144.689546</td>\n",
       "      <td>4843.037238</td>\n",
       "      <td>4374.482421</td>\n",
       "      <td>0.181185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59091</th>\n",
       "      <td>59091</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>First</td>\n",
       "      <td>312</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200633.844449</td>\n",
       "      <td>4144.689546</td>\n",
       "      <td>4843.037238</td>\n",
       "      <td>4374.482421</td>\n",
       "      <td>0.181185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59092</th>\n",
       "      <td>59092</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Second</td>\n",
       "      <td>312</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200633.844449</td>\n",
       "      <td>4144.689546</td>\n",
       "      <td>4843.037238</td>\n",
       "      <td>4374.482421</td>\n",
       "      <td>0.181185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59093 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  beat  beat_num  district  sector  Year Month   Watch  Beat  \\\n",
       "0               0     1      1713        17       1  2015     1   Third  1713   \n",
       "1               1     1      1713        17       1  2015     1  Second  1713   \n",
       "2               2     1      1713        17       1  2015     1   First  1713   \n",
       "3               3     1      1713        17       1  2015     2  Second  1713   \n",
       "4               4     1      1713        17       1  2015     2   Third  1713   \n",
       "...           ...   ...       ...       ...     ...   ...   ...     ...   ...   \n",
       "59088       59088     1       312         3       1  2020    11   Third   312   \n",
       "59089       59089     1       312         3       1  2020    11   First   312   \n",
       "59090       59090     1       312         3       1  2020    12   Third   312   \n",
       "59091       59091     1       312         3       1  2020    12   First   312   \n",
       "59092       59092     1       312         3       1  2020    12  Second   312   \n",
       "\n",
       "       Crimes  ...  count_restaurants  count_bars  count_daycares  \\\n",
       "0          16  ...               63.0         9.0             6.0   \n",
       "1          20  ...               63.0         9.0             6.0   \n",
       "2          14  ...               63.0         9.0             6.0   \n",
       "3          12  ...               63.0         9.0             6.0   \n",
       "4          12  ...               63.0         9.0             6.0   \n",
       "...       ...  ...                ...         ...             ...   \n",
       "59088      35  ...               14.0         1.0             3.0   \n",
       "59089      16  ...               14.0         1.0             3.0   \n",
       "59090      29  ...               14.0         1.0             3.0   \n",
       "59091      19  ...               14.0         1.0             3.0   \n",
       "59092      18  ...               14.0         1.0             3.0   \n",
       "\n",
       "       count_entertainment  count_businesses  road_distance_ft  \\\n",
       "0                      1.0              92.0     169276.405792   \n",
       "1                      1.0              92.0     169276.405792   \n",
       "2                      1.0              92.0     169276.405792   \n",
       "3                      1.0              92.0     169276.405792   \n",
       "4                      1.0              92.0     169276.405792   \n",
       "...                    ...               ...               ...   \n",
       "59088                  1.0              38.0     200633.844449   \n",
       "59089                  1.0              38.0     200633.844449   \n",
       "59090                  1.0              38.0     200633.844449   \n",
       "59091                  1.0              38.0     200633.844449   \n",
       "59092                  1.0              38.0     200633.844449   \n",
       "\n",
       "       TOTAL POPULATION  dist_to_police  dist_to_hospital  high_crime_geog_lag  \n",
       "0          13283.675264     5454.068890       3258.006066             0.155378  \n",
       "1          13283.675264     5454.068890       3258.006066             0.155378  \n",
       "2          13283.675264     5454.068890       3258.006066             0.155378  \n",
       "3          13283.675264     5454.068890       3258.006066             0.155378  \n",
       "4          13283.675264     5454.068890       3258.006066             0.155378  \n",
       "...                 ...             ...               ...                  ...  \n",
       "59088       4144.689546     4843.037238       4374.482421             0.181185  \n",
       "59089       4144.689546     4843.037238       4374.482421             0.181185  \n",
       "59090       4144.689546     4843.037238       4374.482421             0.181185  \n",
       "59091       4144.689546     4843.037238       4374.482421             0.181185  \n",
       "59092       4144.689546     4843.037238       4374.482421             0.181185  \n",
       "\n",
       "[59093 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up test data:\n",
    "data = pd.read_csv(\"../intermediate_data/high_crime_labeled.csv\")\n",
    "#data.head(5)\n",
    "#data[\"was_arrested\"]=data[\"Arrest\"].astype(\"float\")\n",
    "#data = data.drop(\"Arrest\", axis = 1)\n",
    "data = convert_to_categorical(data, [\"Beat\", \"Month\", \"Watch\"])\n",
    "#data.head(5)\n",
    "\n",
    "#data_small = data.sample(frac=0.0001)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "ID                        int64\n",
       "Arrest                     bool\n",
       "Domestic                   bool\n",
       "Beat                   category\n",
       "Year                      int64\n",
       "Month                  category\n",
       "Week                      int64\n",
       "Day                       int64\n",
       "Hour                      int64\n",
       "Watch                  category\n",
       "PRCP                    float64\n",
       "SNOW                    float64\n",
       "TMAX                      int64\n",
       "TMIN                      int64\n",
       "category_1               object\n",
       "category_2               object\n",
       "count_l_stops           float64\n",
       "count_bus_stops         float64\n",
       "count_metra_stops       float64\n",
       "count_restaurants       float64\n",
       "count_bars              float64\n",
       "count_daycares          float64\n",
       "count_entertainment     float64\n",
       "count_businesses        float64\n",
       "road_distance_ft        float64\n",
       "TOTAL POPULATION        float64\n",
       "dist_to_police          float64\n",
       "dist_to_hospital        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  beat  beat_num  district  sector  Year Month   Watch  Beat  \\\n",
      "29557         108     1      1713        17       1  2018     1   First  1713   \n",
      "29558         109     1      1713        17       1  2018     1  Second  1713   \n",
      "29559         110     1      1713        17       1  2018     1   Third  1713   \n",
      "29560         111     1      1713        17       1  2018     2   Third  1713   \n",
      "29561         112     1      1713        17       1  2018     2   First  1713   \n",
      "...           ...   ...       ...       ...     ...   ...   ...     ...   ...   \n",
      "49256       59052     1       312         3       1  2019    11  Second   312   \n",
      "49257       59053     1       312         3       1  2019    11   Third   312   \n",
      "49258       59054     1       312         3       1  2019    12  Second   312   \n",
      "49259       59055     1       312         3       1  2019    12   First   312   \n",
      "49260       59056     1       312         3       1  2019    12   Third   312   \n",
      "\n",
      "       Crimes  ...  count_restaurants  count_bars  count_daycares  \\\n",
      "29557       8  ...               63.0         9.0             6.0   \n",
      "29558      16  ...               63.0         9.0             6.0   \n",
      "29559      24  ...               63.0         9.0             6.0   \n",
      "29560      16  ...               63.0         9.0             6.0   \n",
      "29561       8  ...               63.0         9.0             6.0   \n",
      "...       ...  ...                ...         ...             ...   \n",
      "49256      43  ...               14.0         1.0             3.0   \n",
      "49257      28  ...               14.0         1.0             3.0   \n",
      "49258      33  ...               14.0         1.0             3.0   \n",
      "49259      19  ...               14.0         1.0             3.0   \n",
      "49260      31  ...               14.0         1.0             3.0   \n",
      "\n",
      "       count_entertainment  count_businesses  road_distance_ft  \\\n",
      "29557                  1.0              92.0     169276.405792   \n",
      "29558                  1.0              92.0     169276.405792   \n",
      "29559                  1.0              92.0     169276.405792   \n",
      "29560                  1.0              92.0     169276.405792   \n",
      "29561                  1.0              92.0     169276.405792   \n",
      "...                    ...               ...               ...   \n",
      "49256                  1.0              38.0     200633.844449   \n",
      "49257                  1.0              38.0     200633.844449   \n",
      "49258                  1.0              38.0     200633.844449   \n",
      "49259                  1.0              38.0     200633.844449   \n",
      "49260                  1.0              38.0     200633.844449   \n",
      "\n",
      "       TOTAL POPULATION dist_to_police  dist_to_hospital  high_crime_geog_lag  \n",
      "29557      13283.675264    5454.068890       3258.006066             0.231076  \n",
      "29558      13283.675264    5454.068890       3258.006066             0.231076  \n",
      "29559      13283.675264    5454.068890       3258.006066             0.231076  \n",
      "29560      13283.675264    5454.068890       3258.006066             0.231076  \n",
      "29561      13283.675264    5454.068890       3258.006066             0.231076  \n",
      "...                 ...            ...               ...                  ...  \n",
      "49256       4144.689546    4843.037238       4374.482421             0.174216  \n",
      "49257       4144.689546    4843.037238       4374.482421             0.174216  \n",
      "49258       4144.689546    4843.037238       4374.482421             0.170732  \n",
      "49259       4144.689546    4843.037238       4374.482421             0.174216  \n",
      "49260       4144.689546    4843.037238       4374.482421             0.174216  \n",
      "\n",
      "[19704 rows x 31 columns]\n",
      "       Unnamed: 0  beat  beat_num  district  sector  Year Month   Watch  Beat  \\\n",
      "19712          72     1      1713        17       1  2017     1   First  1713   \n",
      "19713          73     1      1713        17       1  2017     1   Third  1713   \n",
      "19714          74     1      1713        17       1  2017     1  Second  1713   \n",
      "19715          75     1      1713        17       1  2017     2  Second  1713   \n",
      "19716          76     1      1713        17       1  2017     2   Third  1713   \n",
      "...           ...   ...       ...       ...     ...   ...   ...     ...   ...   \n",
      "39402       59016     1       312         3       1  2018    11   Third   312   \n",
      "39403       59017     1       312         3       1  2018    11   First   312   \n",
      "39404       59018     1       312         3       1  2018    12   First   312   \n",
      "39405       59019     1       312         3       1  2018    12  Second   312   \n",
      "39406       59020     1       312         3       1  2018    12   Third   312   \n",
      "\n",
      "       Crimes  ...  count_restaurants  count_bars  count_daycares  \\\n",
      "19712      17  ...               63.0         9.0             6.0   \n",
      "19713      23  ...               63.0         9.0             6.0   \n",
      "19714      17  ...               63.0         9.0             6.0   \n",
      "19715      10  ...               63.0         9.0             6.0   \n",
      "19716      19  ...               63.0         9.0             6.0   \n",
      "...       ...  ...                ...         ...             ...   \n",
      "39402      33  ...               14.0         1.0             3.0   \n",
      "39403      12  ...               14.0         1.0             3.0   \n",
      "39404      15  ...               14.0         1.0             3.0   \n",
      "39405      36  ...               14.0         1.0             3.0   \n",
      "39406      34  ...               14.0         1.0             3.0   \n",
      "\n",
      "       count_entertainment  count_businesses  road_distance_ft  \\\n",
      "19712                  1.0              92.0     169276.405792   \n",
      "19713                  1.0              92.0     169276.405792   \n",
      "19714                  1.0              92.0     169276.405792   \n",
      "19715                  1.0              92.0     169276.405792   \n",
      "19716                  1.0              92.0     169276.405792   \n",
      "...                    ...               ...               ...   \n",
      "39402                  1.0              38.0     200633.844449   \n",
      "39403                  1.0              38.0     200633.844449   \n",
      "39404                  1.0              38.0     200633.844449   \n",
      "39405                  1.0              38.0     200633.844449   \n",
      "39406                  1.0              38.0     200633.844449   \n",
      "\n",
      "       TOTAL POPULATION dist_to_police  dist_to_hospital  high_crime_geog_lag  \n",
      "19712      13283.675264    5454.068890       3258.006066             0.243028  \n",
      "19713      13283.675264    5454.068890       3258.006066             0.243028  \n",
      "19714      13283.675264    5454.068890       3258.006066             0.243028  \n",
      "19715      13283.675264    5454.068890       3258.006066             0.243028  \n",
      "19716      13283.675264    5454.068890       3258.006066             0.243028  \n",
      "...                 ...            ...               ...                  ...  \n",
      "39402       4144.689546    4843.037238       4374.482421             0.104530  \n",
      "39403       4144.689546    4843.037238       4374.482421             0.104530  \n",
      "39404       4144.689546    4843.037238       4374.482421             0.104530  \n",
      "39405       4144.689546    4843.037238       4374.482421             0.101045  \n",
      "39406       4144.689546    4843.037238       4374.482421             0.104530  \n",
      "\n",
      "[19695 rows x 31 columns]\n",
      "       Unnamed: 0  beat  beat_num  district  sector  Year Month   Watch  Beat  \\\n",
      "9861           36     1      1713        17       1  2016     1  Second  1713   \n",
      "9862           37     1      1713        17       1  2016     1   Third  1713   \n",
      "9863           38     1      1713        17       1  2016     1   First  1713   \n",
      "9864           39     1      1713        17       1  2016     2   First  1713   \n",
      "9865           40     1      1713        17       1  2016     2  Second  1713   \n",
      "...           ...   ...       ...       ...     ...   ...   ...     ...   ...   \n",
      "29552       58980     1       312         3       1  2017    11  Second   312   \n",
      "29553       58981     1       312         3       1  2017    11   Third   312   \n",
      "29554       58982     1       312         3       1  2017    12  Second   312   \n",
      "29555       58983     1       312         3       1  2017    12   Third   312   \n",
      "29556       58984     1       312         3       1  2017    12   First   312   \n",
      "\n",
      "       Crimes  ...  count_restaurants  count_bars  count_daycares  \\\n",
      "9861       20  ...               63.0         9.0             6.0   \n",
      "9862       18  ...               63.0         9.0             6.0   \n",
      "9863        8  ...               63.0         9.0             6.0   \n",
      "9864        9  ...               63.0         9.0             6.0   \n",
      "9865       21  ...               63.0         9.0             6.0   \n",
      "...       ...  ...                ...         ...             ...   \n",
      "29552      45  ...               14.0         1.0             3.0   \n",
      "29553      35  ...               14.0         1.0             3.0   \n",
      "29554      29  ...               14.0         1.0             3.0   \n",
      "29555      42  ...               14.0         1.0             3.0   \n",
      "29556      22  ...               14.0         1.0             3.0   \n",
      "\n",
      "       count_entertainment  count_businesses  road_distance_ft  \\\n",
      "9861                   1.0              92.0     169276.405792   \n",
      "9862                   1.0              92.0     169276.405792   \n",
      "9863                   1.0              92.0     169276.405792   \n",
      "9864                   1.0              92.0     169276.405792   \n",
      "9865                   1.0              92.0     169276.405792   \n",
      "...                    ...               ...               ...   \n",
      "29552                  1.0              38.0     200633.844449   \n",
      "29553                  1.0              38.0     200633.844449   \n",
      "29554                  1.0              38.0     200633.844449   \n",
      "29555                  1.0              38.0     200633.844449   \n",
      "29556                  1.0              38.0     200633.844449   \n",
      "\n",
      "       TOTAL POPULATION dist_to_police  dist_to_hospital  high_crime_geog_lag  \n",
      "9861       13283.675264    5454.068890       3258.006066             0.167331  \n",
      "9862       13283.675264    5454.068890       3258.006066             0.167331  \n",
      "9863       13283.675264    5454.068890       3258.006066             0.167331  \n",
      "9864       13283.675264    5454.068890       3258.006066             0.167331  \n",
      "9865       13283.675264    5454.068890       3258.006066             0.167331  \n",
      "...                 ...            ...               ...                  ...  \n",
      "29552       4144.689546    4843.037238       4374.482421             0.135889  \n",
      "29553       4144.689546    4843.037238       4374.482421             0.139373  \n",
      "29554       4144.689546    4843.037238       4374.482421             0.139373  \n",
      "29555       4144.689546    4843.037238       4374.482421             0.139373  \n",
      "29556       4144.689546    4843.037238       4374.482421             0.139373  \n",
      "\n",
      "[19696 rows x 31 columns]\n",
      "       Unnamed: 0  beat  beat_num  district  sector  Year Month   Watch  Beat  \\\n",
      "0               0     1      1713        17       1  2015     1   Third  1713   \n",
      "1               1     1      1713        17       1  2015     1  Second  1713   \n",
      "2               2     1      1713        17       1  2015     1   First  1713   \n",
      "3               3     1      1713        17       1  2015     2  Second  1713   \n",
      "4               4     1      1713        17       1  2015     2   Third  1713   \n",
      "...           ...   ...       ...       ...     ...   ...   ...     ...   ...   \n",
      "19707       58944     1       312         3       1  2016    11   First   312   \n",
      "19708       58945     1       312         3       1  2016    11  Second   312   \n",
      "19709       58946     1       312         3       1  2016    12   First   312   \n",
      "19710       58947     1       312         3       1  2016    12  Second   312   \n",
      "19711       58948     1       312         3       1  2016    12   Third   312   \n",
      "\n",
      "       Crimes  ...  count_restaurants  count_bars  count_daycares  \\\n",
      "0          16  ...               63.0         9.0             6.0   \n",
      "1          20  ...               63.0         9.0             6.0   \n",
      "2          14  ...               63.0         9.0             6.0   \n",
      "3          12  ...               63.0         9.0             6.0   \n",
      "4          12  ...               63.0         9.0             6.0   \n",
      "...       ...  ...                ...         ...             ...   \n",
      "19707      11  ...               14.0         1.0             3.0   \n",
      "19708      40  ...               14.0         1.0             3.0   \n",
      "19709      17  ...               14.0         1.0             3.0   \n",
      "19710      39  ...               14.0         1.0             3.0   \n",
      "19711      42  ...               14.0         1.0             3.0   \n",
      "\n",
      "       count_entertainment  count_businesses  road_distance_ft  \\\n",
      "0                      1.0              92.0     169276.405792   \n",
      "1                      1.0              92.0     169276.405792   \n",
      "2                      1.0              92.0     169276.405792   \n",
      "3                      1.0              92.0     169276.405792   \n",
      "4                      1.0              92.0     169276.405792   \n",
      "...                    ...               ...               ...   \n",
      "19707                  1.0              38.0     200633.844449   \n",
      "19708                  1.0              38.0     200633.844449   \n",
      "19709                  1.0              38.0     200633.844449   \n",
      "19710                  1.0              38.0     200633.844449   \n",
      "19711                  1.0              38.0     200633.844449   \n",
      "\n",
      "       TOTAL POPULATION dist_to_police  dist_to_hospital  high_crime_geog_lag  \n",
      "0          13283.675264    5454.068890       3258.006066             0.155378  \n",
      "1          13283.675264    5454.068890       3258.006066             0.155378  \n",
      "2          13283.675264    5454.068890       3258.006066             0.155378  \n",
      "3          13283.675264    5454.068890       3258.006066             0.155378  \n",
      "4          13283.675264    5454.068890       3258.006066             0.155378  \n",
      "...                 ...            ...               ...                  ...  \n",
      "19707       4144.689546    4843.037238       4374.482421             0.156794  \n",
      "19708       4144.689546    4843.037238       4374.482421             0.156794  \n",
      "19709       4144.689546    4843.037238       4374.482421             0.156794  \n",
      "19710       4144.689546    4843.037238       4374.482421             0.153310  \n",
      "19711       4144.689546    4843.037238       4374.482421             0.153310  \n",
      "\n",
      "[19712 rows x 31 columns]\n",
      "Finished splitting...\n",
      "Working on: [2018 2019]\n",
      "Have accessed train and test df...\n",
      "Finished filling NAs with mean...\n",
      "On to normalizing continuous...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished normalizing training data\n",
      "Finished normalizing test data...\n",
      "Finished one-hot encoding...\n",
      "Finished one-hot encoding...\n",
      "Finished standardizing...\n",
      "0    0.854452\n",
      "1    0.854452\n",
      "2    0.854452\n",
      "3    0.854452\n",
      "4    0.854452\n",
      "Name: principal component 1, dtype: float64\n",
      "(19704, 2) (19704, 328)\n",
      "Working on: [2017 2018]\n",
      "Have accessed train and test df...\n",
      "Finished filling NAs with mean...\n",
      "On to normalizing continuous...\n",
      "Finished normalizing training data\n",
      "Finished normalizing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished one-hot encoding...\n",
      "Finished one-hot encoding...\n",
      "Finished standardizing...\n",
      "0    0.852368\n",
      "1    0.852368\n",
      "2    0.852368\n",
      "3    0.852368\n",
      "4    0.852368\n",
      "Name: principal component 1, dtype: float64\n",
      "(19695, 2) (19695, 328)\n",
      "Working on: [2016 2017]\n",
      "Have accessed train and test df...\n",
      "Finished filling NAs with mean...\n",
      "On to normalizing continuous...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished normalizing training data\n",
      "Finished normalizing test data...\n",
      "Finished one-hot encoding...\n",
      "Finished one-hot encoding...\n",
      "Finished standardizing...\n",
      "0    0.85269\n",
      "1    0.85269\n",
      "2    0.85269\n",
      "3    0.85269\n",
      "4    0.85269\n",
      "Name: principal component 1, dtype: float64\n",
      "(19696, 2) (19696, 328)\n",
      "Working on: [2015 2016]\n",
      "Have accessed train and test df...\n",
      "Finished filling NAs with mean...\n",
      "On to normalizing continuous...\n",
      "Finished normalizing training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "<ipython-input-36-bc70820a9afc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Year\"]=df[\"Year\"].astype(\"category\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished normalizing test data...\n",
      "Finished one-hot encoding...\n",
      "Finished one-hot encoding...\n",
      "Finished standardizing...\n",
      "0    0.856576\n",
      "1    0.856576\n",
      "2    0.856576\n",
      "3    0.856576\n",
      "4    0.856576\n",
      "Name: principal component 1, dtype: float64\n",
      "(19712, 2) (19712, 328)\n"
     ]
    }
   ],
   "source": [
    "#Test the code! \n",
    "#data_list  = prep_data(data, \"high_crime\", 2, \"Year\",  [\"Year\", \"beat_num\", \"district\", \"sector\", \"Month\"], pca=\"conduct\", \n",
    "#                      columns_to_pca = [\"TOTAL POPULATION\", \n",
    "#                       \"dist_to_police\", \"dist_to_hospital\", \"count_l_stops\", \"count_bus_stops\", \n",
    "#                                        \"count_metra_stops\", \"count_restaurants\", \"count_bars\", \n",
    "#                                        \"count_daycares\", \"count_entertainment\", \"count_businesses\", \n",
    "#                                        \"road_distance_ft\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>beat</th>\n",
       "      <th>Watch</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Crimes</th>\n",
       "      <th>Serious</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>PC 1</th>\n",
       "      <th>PC 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29557</th>\n",
       "      <td>-1.727009</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>First</td>\n",
       "      <td>1713</td>\n",
       "      <td>-1.145619</td>\n",
       "      <td>-1.254018</td>\n",
       "      <td>-0.732808</td>\n",
       "      <td>-0.644941</td>\n",
       "      <td>-1.376112</td>\n",
       "      <td>-1.389057</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>-1.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29558</th>\n",
       "      <td>-1.726950</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Second</td>\n",
       "      <td>1713</td>\n",
       "      <td>-0.659307</td>\n",
       "      <td>-0.620498</td>\n",
       "      <td>-0.412349</td>\n",
       "      <td>-0.112728</td>\n",
       "      <td>-1.376112</td>\n",
       "      <td>-1.389057</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>-1.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29559</th>\n",
       "      <td>-1.726892</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Third</td>\n",
       "      <td>1713</td>\n",
       "      <td>-0.172995</td>\n",
       "      <td>-0.348990</td>\n",
       "      <td>-0.252119</td>\n",
       "      <td>-0.112728</td>\n",
       "      <td>-1.376112</td>\n",
       "      <td>-1.389057</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>-1.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29560</th>\n",
       "      <td>-1.726833</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Third</td>\n",
       "      <td>1713</td>\n",
       "      <td>-0.659307</td>\n",
       "      <td>-0.892007</td>\n",
       "      <td>-0.252119</td>\n",
       "      <td>-0.378835</td>\n",
       "      <td>-1.034854</td>\n",
       "      <td>-1.191190</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>-1.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29561</th>\n",
       "      <td>-1.726774</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>First</td>\n",
       "      <td>1713</td>\n",
       "      <td>-1.145619</td>\n",
       "      <td>-0.801504</td>\n",
       "      <td>-0.893037</td>\n",
       "      <td>-0.644941</td>\n",
       "      <td>-1.034854</td>\n",
       "      <td>-1.191190</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>-1.187052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49256</th>\n",
       "      <td>1.727721</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Second</td>\n",
       "      <td>312</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>-0.167984</td>\n",
       "      <td>0.388799</td>\n",
       "      <td>1.750018</td>\n",
       "      <td>-0.829309</td>\n",
       "      <td>-0.790072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.800704</td>\n",
       "      <td>-1.360331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49257</th>\n",
       "      <td>1.727780</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Third</td>\n",
       "      <td>312</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.167984</td>\n",
       "      <td>0.068340</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>-0.829309</td>\n",
       "      <td>-0.790072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.800704</td>\n",
       "      <td>-1.360331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49258</th>\n",
       "      <td>1.727838</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Second</td>\n",
       "      <td>312</td>\n",
       "      <td>0.374107</td>\n",
       "      <td>0.465536</td>\n",
       "      <td>-0.893037</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>-0.886981</td>\n",
       "      <td>-0.889857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.800704</td>\n",
       "      <td>-1.360331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49259</th>\n",
       "      <td>1.727897</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>First</td>\n",
       "      <td>312</td>\n",
       "      <td>-0.476940</td>\n",
       "      <td>-0.711001</td>\n",
       "      <td>-0.252119</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>-0.886981</td>\n",
       "      <td>-0.889857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.800704</td>\n",
       "      <td>-1.360331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49260</th>\n",
       "      <td>1.727955</td>\n",
       "      <td>-1.167287</td>\n",
       "      <td>Third</td>\n",
       "      <td>312</td>\n",
       "      <td>0.252529</td>\n",
       "      <td>-0.167984</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>-0.112728</td>\n",
       "      <td>-0.886981</td>\n",
       "      <td>-0.889857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.800704</td>\n",
       "      <td>-1.360331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19704 rows Ã— 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      beat   Watch  Beat    Crimes   Serious    Arrest  \\\n",
       "29557   -1.727009 -1.167287   First  1713 -1.145619 -1.254018 -0.732808   \n",
       "29558   -1.726950 -1.167287  Second  1713 -0.659307 -0.620498 -0.412349   \n",
       "29559   -1.726892 -1.167287   Third  1713 -0.172995 -0.348990 -0.252119   \n",
       "29560   -1.726833 -1.167287   Third  1713 -0.659307 -0.892007 -0.252119   \n",
       "29561   -1.726774 -1.167287   First  1713 -1.145619 -0.801504 -0.893037   \n",
       "...           ...       ...     ...   ...       ...       ...       ...   \n",
       "49256    1.727721 -1.167287  Second   312  0.981997 -0.167984  0.388799   \n",
       "49257    1.727780 -1.167287   Third   312  0.070162 -0.167984  0.068340   \n",
       "49258    1.727838 -1.167287  Second   312  0.374107  0.465536 -0.893037   \n",
       "49259    1.727897 -1.167287   First   312 -0.476940 -0.711001 -0.252119   \n",
       "49260    1.727955 -1.167287   Third   312  0.252529 -0.167984  0.549029   \n",
       "\n",
       "       Domestic      TMAX      TMIN  ...  Month_5  Month_6 Month_7  Month_8  \\\n",
       "29557 -0.644941 -1.376112 -1.389057  ...        0        0       0        0   \n",
       "29558 -0.112728 -1.376112 -1.389057  ...        0        0       0        0   \n",
       "29559 -0.112728 -1.376112 -1.389057  ...        0        0       0        0   \n",
       "29560 -0.378835 -1.034854 -1.191190  ...        0        0       0        0   \n",
       "29561 -0.644941 -1.034854 -1.191190  ...        0        0       0        0   \n",
       "...         ...       ...       ...  ...      ...      ...     ...      ...   \n",
       "49256  1.750018 -0.829309 -0.790072  ...        0        0       0        0   \n",
       "49257  0.951698 -0.829309 -0.790072  ...        0        0       0        0   \n",
       "49258  0.951698 -0.886981 -0.889857  ...        0        0       0        0   \n",
       "49259  0.951698 -0.886981 -0.889857  ...        0        0       0        0   \n",
       "49260 -0.112728 -0.886981 -0.889857  ...        0        0       0        0   \n",
       "\n",
       "       Month_9  Month_10  Month_11  Month_12      PC 1      PC 2  \n",
       "29557        0         0         0         0  0.854452 -1.187052  \n",
       "29558        0         0         0         0  0.854452 -1.187052  \n",
       "29559        0         0         0         0  0.854452 -1.187052  \n",
       "29560        0         0         0         0  0.854452 -1.187052  \n",
       "29561        0         0         0         0  0.854452 -1.187052  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "49256        0         0         1         0 -0.800704 -1.360331  \n",
       "49257        0         0         1         0 -0.800704 -1.360331  \n",
       "49258        0         0         0         1 -0.800704 -1.360331  \n",
       "49259        0         0         0         1 -0.800704 -1.360331  \n",
       "49260        0         0         0         1 -0.800704 -1.360331  \n",
       "\n",
       "[19704 rows x 330 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(data, y):\n",
    "    '''\n",
    "    Function that separates predictors from target\n",
    "    Inputs:\n",
    "        data (DF): dataframe\n",
    "        y (string): the name of the data column\n",
    "    Outputs:\n",
    "        X_ - df with predictor data\n",
    "        y_ - df with target data\n",
    "    '''\n",
    "    y_ = data[y]\n",
    "    X_ = data.drop(y, axis=1)\n",
    "    \n",
    "    return X_, y_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = split_x_y(data, \"Arrest\")\n",
    "#y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
